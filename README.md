# Amortized_Learning

Исследовательский проект в рамках курсовой работы 

## Описание

Предположим, мы имеем дело с некоторой параметрической вероятностной моделью для (многомерных) временных рядов.


Задача, как обычно, состоит в том, чтобы по пришедшим данным $x_o$ наилучшим образом (что это значит?) 
оценить неизвестный нам вектор параметров модели $\theta$. Разумеется, просто аналитически посчитать правдоподобие 
$p(x_o | \theta)$ (т.е. выписать точную или хотя бы приближённую замкнутую формулу) исторических наблюдений и затем 
как-то максимизировать его (как?) не представляется возможным.


Существует великое множество подходов, предназначенных для борьбы с этой проблемой. 
Некоторые из них предлагают проводить likelihood-free inference (классический пример --- ABC-алгоритм и его модификации), 
другие же (в том числе, Sequential Monte Carlo, известные также как Particle Filters) пытаются вычислить стохастическую оценку
правдоподобия и затем, опционально, на её основе проводить байесовский вывод для поиска апостериорного распределения $p(\theta | x_o)$ 
(например, с помощью Particle MCMC и SMC^2).


Большинство из разработанных ранее методов, к сожалению, обладают рядом серьёзных недостатков: 
существующие алгоритмы довольно быстро упираются в проклятие размерности, невозможность параллелизации на GPU 
и неэффективность case-based scenario. 


Последнее означает, что весь вычислительно трудоёмкий процесс аппроксимации
апостериорного распределения $p(\theta | x_o)$ происходит независимо для каждого конкретного нового пришедшего (из одной и той же вероятностной модели!) временного ряда.

Когда на один запуск такого вывода уходит до 6-8 часов реального времени работы CPU, 
возникает закономерное желание алгоритм амортизировать. 


Иными словами, хочется заранее 
потратить определённое время и вычислительные ресурсы, чтобы обучить некоторый чёрный ящик (нейронную сеть), 
который будет уметь достаточно точно оценивать апостериорное распределение $p(\theta | x)$ при любом $x$ 
(а не только для конкретного единственного $x=x_o$) и проводить каждую такую оценку (обычным прямым проходом через нейронку с уже обученными весами) за доли секунды.


Проект посвящён, по большей части, изучению и применению именно таких амортизированных методов 
(впрочем, не только их: в некоторых случаях себя вполне неплохо показывают и case-based алгоритмы) 
и будет интересен как теоретикам (здесь есть и привычный всем Байесовский вывод, и аппроксимация 
апостериорного распределения через минимизацию $KL$-дивергенции, и вариационные оценки, и теоретические 
вопросы ""вбок"" про разные вероятностные метрики), так и практикам (благо приложений у задачи немало).


На выходе проекта ожидается обзорная заметка или даже статья с полноценной классификацией и систематизацией
имеющихся методов, их анализом и сравнением на базе многочисленных экспериментов, а также с попыткой их улучшить и продвинуть нынешний фронтир.